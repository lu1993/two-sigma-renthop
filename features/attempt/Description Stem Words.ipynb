{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../input/train.json')\n",
    "test_data = pd.read_json('../input/test.json')\n",
    "full_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove punctuation and numbers, stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemming is the process of reducing inflected (or sometimes derived) words to their word stem. \n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Removes symbols, numbers and stem the words to reduce dimentional space\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean(x):\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    # For user clarity, broken it into three steps\n",
    "    i = regex.sub(' ', x).lower()\n",
    "    i = i.split(\" \") \n",
    "    i= [stemmer.stem(l) for l in i]\n",
    "    i= \" \".join([l.strip() for l in i if (len(l)>2) ]) # Keeping words that have length greater than 2\n",
    "    return i\n",
    "\n",
    "# This takes some time to run. It would be helpful if someone can help me optimize clean() function.\n",
    "full_data['description_new'] = full_data.description.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect_desc = CountVectorizer(stop_words='english',max_features=200)\n",
    "full_sparse = cvect_desc.fit_transform(full_data.description_new)\n",
    "# Renaming words to avoid collisions with other feature names in the model\n",
    "col_desc = ['desc_'+ i for i in cvect_desc.get_feature_names()] \n",
    "count_vect_df = pd.DataFrame(full_sparse.todense(), columns=col_desc)\n",
    "full_data = pd.concat([full_data.reset_index(),count_vect_df],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
