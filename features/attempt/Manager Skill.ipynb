{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json(\"../input/train.json\")\n",
    "test_data = pd.read_json(\"../input/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create target variables\n",
    "train_data['target'] = train_data['interest_level'].apply(lambda x: 0 if x=='low' else 1 if x=='medium' else 2)\n",
    "train_data['low'] = train_data['interest_level'].apply(lambda x: 1 if x=='low' else 0)\n",
    "train_data['medium'] = train_data['interest_level'].apply(lambda x: 1 if x=='medium' else 0)\n",
    "train_data['high'] = train_data['interest_level'].apply(lambda x: 1 if x=='high' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic encoding of 'manager_id'\n",
    "from sklearn import preprocessing\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(train_data['manager_id'].values))\n",
    "train_data['manager_id'] = lbl.transform(list(train_data['manager_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to compute interest level fraction and manager skill\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class manager_skill(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold = 5):\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _reset(self):\n",
    "     \n",
    "        if hasattr(self, 'mapping_'):\n",
    "            \n",
    "            self.mapping_ = {}\n",
    "            self.mean_skill_ = 0.0\n",
    "            \n",
    "    def fit(self, X,y):\n",
    "    \n",
    "        self._reset()\n",
    "        \n",
    "        temp = pd.concat([X.manager_id,pd.get_dummies(y)], axis = 1).groupby('manager_id').mean()\n",
    "        temp.columns = ['low_frac', 'medium_frac', 'high_frac']\n",
    "        temp['count'] = X.groupby('manager_id').count().iloc[:,1]\n",
    "        \n",
    "        print(temp.head())\n",
    "\n",
    "        mean = temp.loc[temp['count'] >= self.threshold, ['low_frac', 'medium_frac', 'high_frac']].mean()\n",
    "        \n",
    "        temp.loc[temp['count'] < self.threshold, ['low_frac', 'medium_frac', 'high_frac']] = mean\n",
    "        \n",
    "        self.mapping_ = temp[['low_frac', 'medium_frac', 'high_frac']]\n",
    "        self.mean_skill_ = mean\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X = pd.merge(left = X, right = self.mapping_, how = 'left', left_on = 'manager_id', right_index = True)\n",
    "        X[['low_frac', 'medium_frac', 'high_frac']] = X[['low_frac', 'medium_frac', 'high_frac']].fillna(self.mean_skill_)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use stratified cv to find the optimal parameters\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools as itertools\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_skf_indexes(df, target, kfold=4):\n",
    "    X = df.values\n",
    "    y = df[target].values\n",
    "    skf = StratifiedKFold(n_splits=kfold);\n",
    "    skf.get_n_splits(X, y);\n",
    "    indexes = [[],[]]\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        indexes[0].append(train_index) # Training indexes\n",
    "        indexes[1].append(test_index) # test indexes\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lr_perf(df_train, df_test, feature='__to_check', target='target', n_quantile=20):\n",
    "    results = {}\n",
    "    # Inputs\n",
    "    xtrain = df_train[feature].values.reshape(-1,1)\n",
    "    ytrain = df_train[target].values\n",
    "    xtest = df_test[feature].values.reshape(-1,1)\n",
    "    ytest = df_test[target].values\n",
    "    # Evaluation as a single feature\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(xtrain, ytrain)\n",
    "    yptrain = lr.predict_proba(xtrain)\n",
    "    yptest = lr.predict_proba(xtest)\n",
    "    results['train.num'] = np.round(log_loss(ytrain, yptrain), 6)\n",
    "    results['test.num'] = np.round(log_loss(ytest, yptest), 6)\n",
    "    # Evaluation as a categorical feature using quantile buckets\n",
    "    bins = np.unique(np.percentile(xtrain, np.arange(n_quantile, 100, n_quantile)))\n",
    "    xtrainq = np.digitize(xtrain, bins)\n",
    "    xtestq = np.digitize(xtest, bins)\n",
    "    lb = LabelBinarizer()\n",
    "    x1 = lb.fit_transform(xtrainq)\n",
    "    x2 = lb.transform(xtestq)\n",
    "    lr.fit(x1, ytrain);\n",
    "    yptrain = lr.predict_proba(x1)\n",
    "    yptest = lr.predict_proba(x2)\n",
    "    results['train.cat'] = np.round(log_loss(ytrain, yptrain), 6)\n",
    "    results['test.cat'] = np.round(log_loss(ytest, yptest), 6)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters to check\n",
    "A = tuple(np.arange(0.05,1,0.05))\n",
    "T = tuple(np.arange(5,55,5))\n",
    "\n",
    "# Stratified kfold\n",
    "idx_train, idx_test = get_skf_indexes(train_data, 'target', kfold=4) # kfold=4, set to 2 to quickly run here\n",
    "\n",
    "# Get results\n",
    "Y = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iper,(i_train,i_test) in enumerate(zip(idx_train,idx_test)):\n",
    "    print(iper)\n",
    "    df_train = train_data.iloc[i_train, :].copy()\n",
    "    df_test = train_data.iloc[i_test, :].copy()\n",
    "    # For each parameter combination\n",
    "    for a, t in itertools.product(A,T):\n",
    "        trans = manager_skill(threshold = t)\n",
    "        trans.fit(df_train,df_train['interest_level'])\n",
    "        df_train_transform = trans.transform(df_train)\n",
    "        df_val_transform = trans.transform(df_test)\n",
    "        df_train_transform['__to_check'] = a*df_train_transform['high_frac'] + (1-a)*df_train_transform['medium_frac']\n",
    "        df_val_transform['__to_check'] = a*df_val_transform['high_frac'] + (1-a)*df_val_transform['medium_frac']\n",
    "        results = get_lr_perf(df_train_transform, df_val_transform, feature='__to_check', target='target', n_quantile=20)\n",
    "        results.update({'fold': iper, 'params': {'A':a, 'T': t}})\n",
    "        Y =  Y.append(pd.DataFrame(pd.Series(results)).transpose())\n",
    "for i in ['train.cat', 'train.num', 'test.cat', 'test.num']:\n",
    "    Y[i] = Y[i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y.sort_values(by='test.num',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the average among folds of each parameter combination\n",
    "Y_average = pd.DataFrame(index=range(len(np.unique(Y.params))), columns=['train.cat', 'train.num', 'test.cat', 'test.num'])\n",
    "Y_average = pd.concat([pd.DataFrame({'params':np.unique(Y.params)}),Y_average],axis=1)\n",
    "for i in range(len(np.unique(Y.params))):\n",
    "    param = np.unique(Y.params)[i]\n",
    "    df = Y[Y.params == param][['train.cat', 'train.num', 'test.cat', 'test.num']].mean(axis=1)\n",
    "    Y_average.loc[Y_average.index[i],['train.cat', 'train.num', 'test.cat', 'test.num']] = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_average.sort_values(by='test.num',ascending=True)\n",
    "# a = 0.05, t = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign interest fraction on test dataset\n",
    "trans = manager_skill()\n",
    "trans.fit(train_data, train_data['interest_level'])\n",
    "train_data = trans.transform(train_data)\n",
    "train_data.head()\n",
    "test_data = trans.transform(test_data)\n",
    "test_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
