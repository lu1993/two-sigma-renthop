{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Features ever tried\n",
    "full_data is created in /features/final/features_final.ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Half bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data['half_bathrooms'] = ((np.round(full_data.bathrooms) - full_data.bathrooms)!=0).astype(float) # Half bathrooms? 1.5, 2.5, 3.5..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Duplicate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of duplicates, boolean for duplicates \n",
    "def duplicate(X,columns):\n",
    "    dup_data = X[X.duplicated(columns,keep=False)]\n",
    "    dup_data = dup_data.sort_values(columns,ascending=[True]*len(columns))\n",
    "    keep = dup_data.drop_duplicates(columns,keep='first')\n",
    "    \n",
    "    X['has_dup'] = [0]*X.shape[0]\n",
    "    X['num_dup'] = [1]*X.shape[0]\n",
    "    \n",
    "    for i in range(keep.shape[0]):\n",
    "        df = keep.iloc[i]\n",
    "        dup_df = X[(X[columns] == df[columns]).sum(axis=1) == len(columns)]\n",
    "        X.loc[dup_df.index,'has_dup'] = [1]*dup_df.shape[0]\n",
    "        X.loc[dup_df.index,'num_dup'] = [dup_df.shape[0]]*dup_df.shape[0]\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data = duplicate(full_data,['price', 'latitude', 'longitude', 'bathrooms','bedrooms', 'street_address', 'building_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Address distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data['address_distance'] = [editdistance.eval(x.lower(),y.lower()) for x,y in zip(np.array(full_data.display_address),np.array(full_data.street_address))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Location based price level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=300)\n",
    "price_df = pd.concat([full_data['bedrooms'],full_data['bathrooms'],full_data['latitude'],full_data['longitude'],full_data['price']], axis=1)\n",
    "model.fit(price_df.drop(['price'], axis=1), price_df['price'])\n",
    "pred_price = model.predict(price_df.drop(['price'], axis=1))\n",
    "price_df['predicted_price'] = pd.DataFrame(pred_price, columns=['predicted_price'])\n",
    "price_df['pred_price_ratio'] = price_df['price'] / price_df['predicted_price']\n",
    "full_data['pred_price_ratio'] = price_df['pred_price_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Price per sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "A = 1\n",
    "B = 0.5\n",
    "C = [1,4]\n",
    "D = [0,2]\n",
    "full_data['price_per_sqft'] = (full_data.price / (A + full_data.bedrooms.clip(C[0], C[1]) + B*full_data.bathrooms.clip(D[0], D[1]))).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Manager Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# functions to compute interest level fraction and manager skill\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class manager_skill(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold = 5):\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _reset(self):\n",
    "     \n",
    "        if hasattr(self, 'mapping_'):\n",
    "            \n",
    "            self.mapping_ = {}\n",
    "            self.mean_skill_ = 0.0\n",
    "            \n",
    "    def fit(self, X,y):\n",
    "    \n",
    "        self._reset()\n",
    "        \n",
    "        temp = pd.concat([X.manager_id,pd.get_dummies(y)], axis = 1).groupby('manager_id').mean()\n",
    "        temp.columns = ['low_frac', 'medium_frac', 'high_frac']\n",
    "        temp['count'] = X.groupby('manager_id').count().iloc[:,1]\n",
    "        \n",
    "        print(temp.head())\n",
    "\n",
    "        mean = temp.loc[temp['count'] >= self.threshold, ['low_frac', 'medium_frac', 'high_frac']].mean()\n",
    "        \n",
    "        temp.loc[temp['count'] < self.threshold, ['low_frac', 'medium_frac', 'high_frac']] = mean\n",
    "        \n",
    "        self.mapping_ = temp[['low_frac', 'medium_frac', 'high_frac']]\n",
    "        self.mean_skill_ = mean\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X = pd.merge(left = X, right = self.mapping_, how = 'left', left_on = 'manager_id', right_index = True)\n",
    "        X[['low_frac', 'medium_frac', 'high_frac']] = X[['low_frac', 'medium_frac', 'high_frac']].fillna(self.mean_skill_)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = full_data.iloc[0:train_data.shape[0]]\n",
    "test_data = full_data.iloc[train_data.shape[0]:full_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "[train_data.shape[0],test_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# assign interest fraction on test dataset\n",
    "trans = manager_skill()\n",
    "trans.fit(train_data, train_data['interest_level'])\n",
    "train_data = trans.transform(train_data)\n",
    "train_data.head()\n",
    "test_data = trans.transform(test_data)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data=pd.concat([train_data\n",
    "                       ,test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training data size: ', (49352, 261), 'testing data size: ', (74659, 261))\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##Baseline with features from \"features\" and street address\n",
    "\n",
    "full_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars + LE_vars + hcc_vars + num_cat_vars + img_vars # + additioanl_vars\n",
    "\n",
    "train_x = sparse.hstack([full_data[full_vars], feature_sparse,st_addr_sparse]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "\n",
    "test_x = sparse.hstack([full_data[full_vars], feature_sparse,st_addr_sparse]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + st_addr_vars\n",
    "print (\"training data size: \", train_x.shape,\"testing data size: \", test_x.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
